{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9442d81c",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "!pip install transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dde2c0",
   "metadata": {},
   "source": [
    "# Load our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d621c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"correct\", 1: \"incorrect\"}\n",
    "label2id = {\"incorrect\": 0, \"correct\": 1}\n",
    "\n",
    "# Model Architecture\n",
    "myTokenizer = AutoTokenizer.from_pretrained(\"mideind/IceBERT\")\n",
    "myModel = AutoModelForSequenceClassification.from_pretrained(\"refactored_model_v2_318k\", num_labels=2, id2label=id2label, label2id=label2id)\n",
    "classifier = pipeline(\"text-classification\", model=myModel, tokenizer=myTokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441640b1",
   "metadata": {},
   "source": [
    "# Load our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc814526",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data = pd.read_csv(\"./original_datasets/Storasnid_beygm.csv\", low_memory=False, encoding='latin-1', header=None, sep=\";\")\n",
    "# Drop unused columns\n",
    "case_data = bin_data.drop([0,2,5,6,7], axis=1)\n",
    "case_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35f136b",
   "metadata": {},
   "source": [
    "# Functions meant to be abstracted from the interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that returns an 3d array of possible cases, in the form of:\n",
    "# [[original_word,[possible_case_1,possible_case_2,...,possible_case_n],[next_word_in_sentence,[possible_case_1]]...]\n",
    "def find_alternate_cases(myText):\n",
    "    # Make an array to contain all the cases we want to test\n",
    "    words_to_test=[]\n",
    "\n",
    "    #for each word in the string find it's case alternatives if they exist, and add them to the array\n",
    "    word_array = myText.split()\n",
    "    for word in word_array:\n",
    "        alt_cases = []\n",
    "        df_same_words = case_data.loc[case_data[3] == word]\n",
    "        if not df_same_words.empty:\n",
    "            word_matches = df_same_words[1].unique()\n",
    "            for word_id in word_matches:\n",
    "                df_alt_cases = case_data.loc[case_data[1] == word_id]\n",
    "                df_alt_cases = df_alt_cases[3].unique()\n",
    "                df_alt_cases = df_alt_cases[df_alt_cases != word]\n",
    "                words_to_test.append([word,df_alt_cases])\n",
    "    return words_to_test\n",
    "\n",
    "def test_alternate_cases(test_sentence, words_to_test):\n",
    "    \n",
    "    prediction = classifier(test_sentence)\n",
    "    print(\"I think this sentence is\",prediction[0]['label'],\"--> \",test_sentence)\n",
    "    if prediction[0]['label'] == 'correct':\n",
    "        return False\n",
    "    # Create an array to hold our suggestions in\n",
    "    suggestions = []\n",
    "    word_array = test_sentence.split()\n",
    "\n",
    "    # Create the sentence to be tested\n",
    "    for word in words_to_test:\n",
    "        index = word_array.index(word[0])\n",
    "        #test_sentence.split()\n",
    "        for case in word[1]:\n",
    "            test_sentence = word_array.copy()\n",
    "            test_sentence[index] = case\n",
    "            # Test the sentence, and if it scores correct, log it\n",
    "            test_sentence = \" \".join(test_sentence)\n",
    "            prediction = classifier(test_sentence)\n",
    "            if prediction[0]['label'] == 'correct':\n",
    "                suggestions.append([test_sentence, prediction[0]['score']])\n",
    "    return suggestions\n",
    "            \n",
    "def print_suggestions(suggestions):\n",
    "    suggestions.sort(key=lambda suggestions:suggestions[1])\n",
    "    print(\"             Did you mean --> \", suggestions[-1][0])\n",
    "    \n",
    "    #for x in range(len(suggestions)-1):\n",
    "        #print(\"Or possibly --> \", suggestions[x][0])\n",
    "        #print(\"-_-_--_-_--_-_--_-_--_-_-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c928f",
   "metadata": {},
   "source": [
    "# GEC Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d0b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the csv file, and read each sentence\n",
    "with open('./original_datasets/ChatGPT_comparison.csv') as csv_file:\n",
    "    file_to_be_proofread = csv.reader(csv_file)\n",
    "    for line in file_to_be_proofread:\n",
    "        my_text = line[0]\n",
    "        words_to_test = find_alternate_cases(my_text)\n",
    "        suggestions = test_alternate_cases(my_text,words_to_test)\n",
    "        if suggestions:\n",
    "            print_suggestions(suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6bc9a5",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce74ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sentences = []\n",
    "incorrect_sentences = []\n",
    "\n",
    "correct_suggestions = 0\n",
    "incorrect_suggestions = 0\n",
    "no_suggestions = 0\n",
    "returned_false = 0\n",
    "\n",
    "mismatches = []\n",
    "\n",
    "with open('./generated_datasets/correct_sentence_data.csv') as csv_file:\n",
    "    my_file = csv.reader(csv_file)\n",
    "    next(my_file, None)  # skip the header\n",
    "    for line in my_file:\n",
    "        correct_sentences.append([line[0]])\n",
    "        \n",
    "with open('./generated_datasets/incorrect_sentence_data.csv') as csv_file:\n",
    "    my_file = csv.reader(csv_file)\n",
    "    next(my_file, None)  # skip the header\n",
    "    for line in my_file:\n",
    "        incorrect_sentences.append([line[0]])\n",
    "        \n",
    "for i in range(len(correct_sentences)):\n",
    "    if(i%10==0):\n",
    "        print(\"We are at sentence: \",i)\n",
    "    correct_sentence = correct_sentences[i][0]\n",
    "    incorrect_sentence = incorrect_sentences[i][0]\n",
    "    suggested_sentence = \"\"\n",
    "    words_to_test = find_alternate_cases(incorrect_sentence)\n",
    "    suggestions = test_alternate_cases(incorrect_sentence,words_to_test)\n",
    "    if suggestions:\n",
    "        suggestions.sort(key=lambda suggestions:suggestions[1])\n",
    "        suggested_sentence = suggestions[-1][0]\n",
    "        if(suggested_sentence==correct_sentence):\n",
    "            correct_suggestions += 1\n",
    "        else:\n",
    "            incorrect_suggestions += 1\n",
    "            mismatches.append([incorrect_sentence,suggested_sentence,correct_sentence])\n",
    "    elif suggestions == False:\n",
    "        returned_false += 1\n",
    "    else:\n",
    "        no_suggestions += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eaf55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(incorrect_sentences)\n",
    "\n",
    "print(\"correct_suggestions :\",correct_suggestions,\" : \",1/total*correct_suggestions)\n",
    "print(\"incorrect_suggestions :\",incorrect_suggestions,\" : \",1/total*incorrect_suggestions)\n",
    "print(\"no_suggestions :\",no_suggestions,\" : \",1/total*no_suggestions)\n",
    "print(\"misclassified :\",returned_false,\" : \",1/total*returned_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95834d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mismatch in mismatches:\n",
    "    print(\"----------------------------------\")\n",
    "    print(mismatch[0]) # Incorrect\n",
    "    print(\"-\")\n",
    "    print(mismatch[1]) # Suggested\n",
    "    print(\"-\")\n",
    "    print(mismatch[2]) # Corrected\n",
    "    print(\"----------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
